{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajshekhar-Reddy1/-Insaid-AI-Regards/blob/main/NLP2_Module1_Assignment_Solutions_ipynb_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAGUqDTzw9Up"
      },
      "source": [
        "<center><img src=\"https://github.com/insaid2018/Term-1/blob/master/Images/INSAID_Full%20Logo.png?raw=true\" width=\"240\" height=\"100\" /></center>\n",
        "\n",
        "**<center><h3>NLP2 Module 1 Assignment Solutions</h3></center>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHHwrIpovSbU"
      },
      "source": [
        "---\n",
        "# **Table of Contents**\n",
        "---\n",
        "\n",
        "**1.** [**Dataset Description**](#Section1)<br>\n",
        "**2.** [**Importing Libraries**](#Section2)<br>\n",
        "**3.** [**Importing the Dataset**](#Section3)<br>\n",
        "**4.** [**Data Pre-processing**](#Section4)<br>\n",
        "**5.** [**Building LSTM Model**](#Section5)<br>\n",
        "**6.** [**Generating Text with LSTM Network**](#Section6)<br>\n",
        "**7.** [**Data Post-Processing**](#Section7)<br>\n",
        "**8.** [**Building Larger LSTM Network**](#Section8)<br>\n",
        "**9.** [**Generating Text**](#Section9)<br>\n",
        "**10.** [**Conclusion**](#Section9)<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ux4mhGAmw9U1"
      },
      "source": [
        "---\n",
        "<a name = Section1></a>\n",
        "# **1. Dataset Description**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REB21MaBw9U1"
      },
      "source": [
        " - We are going to use __The Adventures of Sherlock Holmes__ as the dataset.\n",
        "\n",
        "<center><img src=\"https://raw.githubusercontent.com/insaid2018/DeepLearning/master/images/Adventures_of_sherlock_holmes.jpg\" /></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-EzcqElBw9U2"
      },
      "source": [
        "---\n",
        "<a name = Section2></a>\n",
        "# **2. Importing Libraries**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbA6heuJiBC5"
      },
      "source": [
        "# Import tensorflow 2.x\n",
        "# This code block will only work in Google Colab.\n",
        "try:\n",
        "    # %tensorflow_version only exists in Colab.\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We__8eOQw9U3"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wuAGDoNirfi"
      },
      "source": [
        "import numpy as np\n",
        "import urllib\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvNpFY076p5m"
      },
      "source": [
        "---\n",
        "<a name = Section3></a>\n",
        "# **3. Importing the Dataset**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3urCxe6rIsp"
      },
      "source": [
        "# Importing the dataset from github.\n",
        "response = urllib.request.urlopen('https://raw.githubusercontent.com/insaid2018/DeepLearning/master/Data/The%20Adventures%20of%20Sherlock%20Holmes.txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2A05TLSRcMw"
      },
      "source": [
        "**<h4>Question 1:** Complete the function to read the text from the `response` object.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Use the `read` method of the `response` object and **decode** the text using **utf8**.\n",
        "\n",
        "- Convert the entire text to **lower** case.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "Pno0Jnlbyahf"
      },
      "source": [
        "def read_text(response):\n",
        "    # Read the text and decode it.\n",
        "    raw_text = response.read().decode('utf8')\n",
        "\n",
        "    # Convert the entire text to lower case.\n",
        "    raw_text = raw_text.lower()\n",
        "\n",
        "    return raw_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SoBMCcxBR3z0"
      },
      "source": [
        "raw_text = read_text(response)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDO1Spt4RElx"
      },
      "source": [
        "---\n",
        "<a name = Section4></a>\n",
        "# **4. Data Pre-processing**\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bqCp0DCw9VI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc4fdc9-41ff-4c3c-9d81-00c45ade2a96"
      },
      "source": [
        "print(raw_text[:1000])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "i. a scandal in bohemia\r\n",
            "\r\n",
            "to sherlock holmes she is always _the_ woman. i have seldom heard him\r\n",
            "mention her under any other name. in his eyes she eclipses and\r\n",
            "predominates the whole of her sex. it was not that he felt any emotion\r\n",
            "akin to love for irene adler. all emotions, and that one particularly,\r\n",
            "were abhorrent to his cold, precise but admirably balanced mind. he\r\n",
            "was, i take it, the most perfect reasoning and observing machine that\r\n",
            "the world has seen, but as a lover he would have placed himself in a\r\n",
            "false position. he never spoke of the softer passions, save with a gibe\r\n",
            "and a sneer. they were admirable things for the observer—excellent for\r\n",
            "drawing the veil from men’s motives and actions. but for the trained\r\n",
            "reasoner to admit such intrusions into his own delicate and finely\r\n",
            "adjusted temperament was to introduce a distracting factor which might\r\n",
            "throw a doubt upon all his mental results. grit in a sensitive\r\n",
            "instrument, or a crack in one of his own high-power lenses, would\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zULX-8H8RMaT"
      },
      "source": [
        "**<h4>Question 2:** Create mapping of unique chars to integers.\n",
        "\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Create a dictionary with the mapping, where **character** should be the **key** and it's **index** should be the **value**.\n",
        "\n",
        "- Perform the operation on the **chars** list.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFyFuPSXw9VL"
      },
      "source": [
        "chars = sorted(list(set(raw_text)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bxn8F9-0w9VN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6eeee28-1c26-4ca8-8b00-5256886067f7"
      },
      "source": [
        "chars[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '\\r',\n",
              " ' ',\n",
              " '!',\n",
              " '&',\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYfwT1hlSsrJ"
      },
      "source": [
        "def char_mapping(chars):\n",
        "    char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
        "\n",
        "    return char_to_int"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tr_OihyDTJQg"
      },
      "source": [
        "char_to_int = char_mapping(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1bq6-Y4w9VQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7967bff-bec7-416f-f5f5-dea97c7c2319"
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " '\\r': 1,\n",
              " ' ': 2,\n",
              " '!': 3,\n",
              " '&': 4,\n",
              " '(': 5,\n",
              " ')': 6,\n",
              " ',': 7,\n",
              " '-': 8,\n",
              " '.': 9,\n",
              " '0': 10,\n",
              " '1': 11,\n",
              " '2': 12,\n",
              " '3': 13,\n",
              " '4': 14,\n",
              " '5': 15,\n",
              " '6': 16,\n",
              " '7': 17,\n",
              " '8': 18,\n",
              " '9': 19,\n",
              " ':': 20,\n",
              " ';': 21,\n",
              " '?': 22,\n",
              " '_': 23,\n",
              " 'a': 24,\n",
              " 'b': 25,\n",
              " 'c': 26,\n",
              " 'd': 27,\n",
              " 'e': 28,\n",
              " 'f': 29,\n",
              " 'g': 30,\n",
              " 'h': 31,\n",
              " 'i': 32,\n",
              " 'j': 33,\n",
              " 'k': 34,\n",
              " 'l': 35,\n",
              " 'm': 36,\n",
              " 'n': 37,\n",
              " 'o': 38,\n",
              " 'p': 39,\n",
              " 'q': 40,\n",
              " 'r': 41,\n",
              " 's': 42,\n",
              " 't': 43,\n",
              " 'u': 44,\n",
              " 'v': 45,\n",
              " 'w': 46,\n",
              " 'x': 47,\n",
              " 'y': 48,\n",
              " 'z': 49,\n",
              " '£': 50,\n",
              " '½': 51,\n",
              " 'à': 52,\n",
              " 'â': 53,\n",
              " 'æ': 54,\n",
              " 'è': 55,\n",
              " 'é': 56,\n",
              " 'œ': 57,\n",
              " '—': 58,\n",
              " '‘': 59,\n",
              " '’': 60,\n",
              " '“': 61,\n",
              " '”': 62}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNxNYjSjw9VV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee37c522-14a2-486f-84fd-ba0ffadc5e89"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Unique Vocab: \", n_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  573498\n",
            "Total Unique Vocab:  63\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCXln1peYgW5"
      },
      "source": [
        "**<h4>Question 3:** Create input and output variables.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        " - **Split** the book text up into **subsequences** with a fixed length of **100 characters**, an arbitrary length, which is specified by **maxlen**.\n",
        "\n",
        " - Each training pattern of the network should be comprised of **100 time steps of one character (X) followed by one character output (y).** When creating these sequences, slide this window along the whole book one character at a time, allowing each character a chance to be learned from the 100 characters that preceded it. The sliding window movement is specified by **step**.\n",
        "\n",
        " - For example, if the sequence length is 5 (for simplicity) then the first two training patterns would be as follows:\n",
        "\n",
        "  CHAPT -> E <br/>\n",
        "  \n",
        "  HAPTE -> R\n",
        "\n",
        "- Append each sequence to the **sentences** list and each next character to the **next_chars** list.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wS5IYd9XKld"
      },
      "source": [
        "maxlen = 100\n",
        "step = 1\n",
        "sentences = []\n",
        "next_chars = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0xuQVsXw9Va"
      },
      "source": [
        "def input_output(raw_text, maxlen, step):\n",
        "    for i in range(0, len(raw_text) - maxlen, step):\n",
        "        sentences.append(raw_text[i: i + maxlen])\n",
        "        next_chars.append(raw_text[i + maxlen])\n",
        "    \n",
        "    return sentences, next_chars"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekxaIjAdYL2L"
      },
      "source": [
        "sentences, next_chars = input_output(raw_text, maxlen, step)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVpizRKbXM8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e36d634-fa22-4d70-b2b0-c69ddea0cef4"
      },
      "source": [
        "print('Number of sequences:', len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of sequences: 573398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91JQrMKAw9Vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80c77e01-f292-4f96-edcc-2d07cf04b7a4"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i. a scandal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nme',\n",
              " '. a scandal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmen',\n",
              " ' a scandal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nment',\n",
              " 'a scandal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmenti',\n",
              " ' scandal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmentio',\n",
              " 'scandal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmention',\n",
              " 'candal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmention ',\n",
              " 'andal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmention h',\n",
              " 'ndal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmention he',\n",
              " 'dal in bohemia\\r\\n\\r\\nto sherlock holmes she is always _the_ woman. i have seldom heard him\\r\\nmention her']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iERDpcW4w9Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2b40efd-90d8-4a65-8d21-5d82b2dd4685"
      },
      "source": [
        "next_chars[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n', 't', 'i', 'o', 'n', ' ', 'h', 'e', 'r', ' ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LbUMwHJw9Vk"
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnoC0kkBw9Vj"
      },
      "source": [
        "**<h4>Question 4:** Complete the function to convert the characters to integers using **char_to_int**.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        " - Append the integer version of the sequences to **dataX** list.\n",
        "\n",
        " - Append the integer version of the next character to **dataY** list.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJoe1cpscSkp"
      },
      "source": [
        "def char_to_int_fn(n_chars, seq_length, raw_text, char_to_int):\n",
        "    for i in range(0, n_chars - seq_length, 1):\n",
        "        seq_in = raw_text[i:i + seq_length]\n",
        "        seq_out = raw_text[i + seq_length]\n",
        "        dataX.append([char_to_int[char] for char in seq_in])\n",
        "        dataY.append(char_to_int[seq_out])\n",
        "\n",
        "    return dataX, dataY"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XsbKcX4cHA2"
      },
      "source": [
        "dataX, dataY = char_to_int_fn(n_chars, seq_length, raw_text, char_to_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE1s3TBucG8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53923d7-a006-4a5a-cd92-0d4c252814a2"
      },
      "source": [
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  573398\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_RRHS-Mw9Vm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24581af7-3a8a-4ae2-aa0e-bde6418f120f"
      },
      "source": [
        "dataX[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[32,\n",
              "  9,\n",
              "  2,\n",
              "  24,\n",
              "  2,\n",
              "  42,\n",
              "  26,\n",
              "  24,\n",
              "  37,\n",
              "  27,\n",
              "  24,\n",
              "  35,\n",
              "  2,\n",
              "  32,\n",
              "  37,\n",
              "  2,\n",
              "  25,\n",
              "  38,\n",
              "  31,\n",
              "  28,\n",
              "  36,\n",
              "  32,\n",
              "  24,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  43,\n",
              "  38,\n",
              "  2,\n",
              "  42,\n",
              "  31,\n",
              "  28,\n",
              "  41,\n",
              "  35,\n",
              "  38,\n",
              "  26,\n",
              "  34,\n",
              "  2,\n",
              "  31,\n",
              "  38,\n",
              "  35,\n",
              "  36,\n",
              "  28,\n",
              "  42,\n",
              "  2,\n",
              "  42,\n",
              "  31,\n",
              "  28,\n",
              "  2,\n",
              "  32,\n",
              "  42,\n",
              "  2,\n",
              "  24,\n",
              "  35,\n",
              "  46,\n",
              "  24,\n",
              "  48,\n",
              "  42,\n",
              "  2,\n",
              "  23,\n",
              "  43,\n",
              "  31,\n",
              "  28,\n",
              "  23,\n",
              "  2,\n",
              "  46,\n",
              "  38,\n",
              "  36,\n",
              "  24,\n",
              "  37,\n",
              "  9,\n",
              "  2,\n",
              "  32,\n",
              "  2,\n",
              "  31,\n",
              "  24,\n",
              "  45,\n",
              "  28,\n",
              "  2,\n",
              "  42,\n",
              "  28,\n",
              "  35,\n",
              "  27,\n",
              "  38,\n",
              "  36,\n",
              "  2,\n",
              "  31,\n",
              "  28,\n",
              "  24,\n",
              "  41,\n",
              "  27,\n",
              "  2,\n",
              "  31,\n",
              "  32,\n",
              "  36,\n",
              "  1,\n",
              "  0,\n",
              "  36,\n",
              "  28],\n",
              " [9,\n",
              "  2,\n",
              "  24,\n",
              "  2,\n",
              "  42,\n",
              "  26,\n",
              "  24,\n",
              "  37,\n",
              "  27,\n",
              "  24,\n",
              "  35,\n",
              "  2,\n",
              "  32,\n",
              "  37,\n",
              "  2,\n",
              "  25,\n",
              "  38,\n",
              "  31,\n",
              "  28,\n",
              "  36,\n",
              "  32,\n",
              "  24,\n",
              "  1,\n",
              "  0,\n",
              "  1,\n",
              "  0,\n",
              "  43,\n",
              "  38,\n",
              "  2,\n",
              "  42,\n",
              "  31,\n",
              "  28,\n",
              "  41,\n",
              "  35,\n",
              "  38,\n",
              "  26,\n",
              "  34,\n",
              "  2,\n",
              "  31,\n",
              "  38,\n",
              "  35,\n",
              "  36,\n",
              "  28,\n",
              "  42,\n",
              "  2,\n",
              "  42,\n",
              "  31,\n",
              "  28,\n",
              "  2,\n",
              "  32,\n",
              "  42,\n",
              "  2,\n",
              "  24,\n",
              "  35,\n",
              "  46,\n",
              "  24,\n",
              "  48,\n",
              "  42,\n",
              "  2,\n",
              "  23,\n",
              "  43,\n",
              "  31,\n",
              "  28,\n",
              "  23,\n",
              "  2,\n",
              "  46,\n",
              "  38,\n",
              "  36,\n",
              "  24,\n",
              "  37,\n",
              "  9,\n",
              "  2,\n",
              "  32,\n",
              "  2,\n",
              "  31,\n",
              "  24,\n",
              "  45,\n",
              "  28,\n",
              "  2,\n",
              "  42,\n",
              "  28,\n",
              "  35,\n",
              "  27,\n",
              "  38,\n",
              "  36,\n",
              "  2,\n",
              "  31,\n",
              "  28,\n",
              "  24,\n",
              "  41,\n",
              "  27,\n",
              "  2,\n",
              "  31,\n",
              "  32,\n",
              "  36,\n",
              "  1,\n",
              "  0,\n",
              "  36,\n",
              "  28,\n",
              "  37]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnJhxw2bw9Vo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545bc7be-9b3b-4ec9-e4d9-9e206fe23e0b"
      },
      "source": [
        "dataY[:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[37, 43]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzxgzeNAw9Vq"
      },
      "source": [
        " - Now that we have **prepared our training data we need to transform it so that it is suitable for use with Keras.**\n",
        "\n",
        "\n",
        " - First we must **transform the list of input sequences into the form [samples, time steps, features] expected by an LSTM network.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-ND1kvGw9Vr"
      },
      "source": [
        "# Reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsbmGs8Yw9Vt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9de995f-78c8-492c-8419-1727ad3926eb"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(573398, 100, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcfM23BHw9Vv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b52c91c-e42f-4dfe-d4b2-38583637b149"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32],\n",
              "       [ 9],\n",
              "       [ 2],\n",
              "       [24],\n",
              "       [ 2],\n",
              "       [42],\n",
              "       [26],\n",
              "       [24],\n",
              "       [37],\n",
              "       [27],\n",
              "       [24],\n",
              "       [35],\n",
              "       [ 2],\n",
              "       [32],\n",
              "       [37],\n",
              "       [ 2],\n",
              "       [25],\n",
              "       [38],\n",
              "       [31],\n",
              "       [28],\n",
              "       [36],\n",
              "       [32],\n",
              "       [24],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [43],\n",
              "       [38],\n",
              "       [ 2],\n",
              "       [42],\n",
              "       [31],\n",
              "       [28],\n",
              "       [41],\n",
              "       [35],\n",
              "       [38],\n",
              "       [26],\n",
              "       [34],\n",
              "       [ 2],\n",
              "       [31],\n",
              "       [38],\n",
              "       [35],\n",
              "       [36],\n",
              "       [28],\n",
              "       [42],\n",
              "       [ 2],\n",
              "       [42],\n",
              "       [31],\n",
              "       [28],\n",
              "       [ 2],\n",
              "       [32],\n",
              "       [42],\n",
              "       [ 2],\n",
              "       [24],\n",
              "       [35],\n",
              "       [46],\n",
              "       [24],\n",
              "       [48],\n",
              "       [42],\n",
              "       [ 2],\n",
              "       [23],\n",
              "       [43],\n",
              "       [31],\n",
              "       [28],\n",
              "       [23],\n",
              "       [ 2],\n",
              "       [46],\n",
              "       [38],\n",
              "       [36],\n",
              "       [24],\n",
              "       [37],\n",
              "       [ 9],\n",
              "       [ 2],\n",
              "       [32],\n",
              "       [ 2],\n",
              "       [31],\n",
              "       [24],\n",
              "       [45],\n",
              "       [28],\n",
              "       [ 2],\n",
              "       [42],\n",
              "       [28],\n",
              "       [35],\n",
              "       [27],\n",
              "       [38],\n",
              "       [36],\n",
              "       [ 2],\n",
              "       [31],\n",
              "       [28],\n",
              "       [24],\n",
              "       [41],\n",
              "       [27],\n",
              "       [ 2],\n",
              "       [31],\n",
              "       [32],\n",
              "       [36],\n",
              "       [ 1],\n",
              "       [ 0],\n",
              "       [36],\n",
              "       [28]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPaZFeohw9V1"
      },
      "source": [
        " - Next we need to rescale the integers to the **range 0-to-1** to make the patterns easier to learn by the LSTM network that uses the **sigmoid activation function** by default."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA4O57Y9w9V2"
      },
      "source": [
        "# Normalizing the data.\n",
        "X = X / float(n_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjCAzXREw9V9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c3b6b2-4412-42ca-ae6a-8cdfa9a49aae"
      },
      "source": [
        "X[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.50793651],\n",
              "       [0.14285714],\n",
              "       [0.03174603],\n",
              "       [0.38095238],\n",
              "       [0.03174603],\n",
              "       [0.66666667],\n",
              "       [0.41269841],\n",
              "       [0.38095238],\n",
              "       [0.58730159],\n",
              "       [0.42857143],\n",
              "       [0.38095238],\n",
              "       [0.55555556],\n",
              "       [0.03174603],\n",
              "       [0.50793651],\n",
              "       [0.58730159],\n",
              "       [0.03174603],\n",
              "       [0.3968254 ],\n",
              "       [0.6031746 ],\n",
              "       [0.49206349],\n",
              "       [0.44444444],\n",
              "       [0.57142857],\n",
              "       [0.50793651],\n",
              "       [0.38095238],\n",
              "       [0.01587302],\n",
              "       [0.        ],\n",
              "       [0.01587302],\n",
              "       [0.        ],\n",
              "       [0.68253968],\n",
              "       [0.6031746 ],\n",
              "       [0.03174603],\n",
              "       [0.66666667],\n",
              "       [0.49206349],\n",
              "       [0.44444444],\n",
              "       [0.65079365],\n",
              "       [0.55555556],\n",
              "       [0.6031746 ],\n",
              "       [0.41269841],\n",
              "       [0.53968254],\n",
              "       [0.03174603],\n",
              "       [0.49206349],\n",
              "       [0.6031746 ],\n",
              "       [0.55555556],\n",
              "       [0.57142857],\n",
              "       [0.44444444],\n",
              "       [0.66666667],\n",
              "       [0.03174603],\n",
              "       [0.66666667],\n",
              "       [0.49206349],\n",
              "       [0.44444444],\n",
              "       [0.03174603],\n",
              "       [0.50793651],\n",
              "       [0.66666667],\n",
              "       [0.03174603],\n",
              "       [0.38095238],\n",
              "       [0.55555556],\n",
              "       [0.73015873],\n",
              "       [0.38095238],\n",
              "       [0.76190476],\n",
              "       [0.66666667],\n",
              "       [0.03174603],\n",
              "       [0.36507937],\n",
              "       [0.68253968],\n",
              "       [0.49206349],\n",
              "       [0.44444444],\n",
              "       [0.36507937],\n",
              "       [0.03174603],\n",
              "       [0.73015873],\n",
              "       [0.6031746 ],\n",
              "       [0.57142857],\n",
              "       [0.38095238],\n",
              "       [0.58730159],\n",
              "       [0.14285714],\n",
              "       [0.03174603],\n",
              "       [0.50793651],\n",
              "       [0.03174603],\n",
              "       [0.49206349],\n",
              "       [0.38095238],\n",
              "       [0.71428571],\n",
              "       [0.44444444],\n",
              "       [0.03174603],\n",
              "       [0.66666667],\n",
              "       [0.44444444],\n",
              "       [0.55555556],\n",
              "       [0.42857143],\n",
              "       [0.6031746 ],\n",
              "       [0.57142857],\n",
              "       [0.03174603],\n",
              "       [0.49206349],\n",
              "       [0.44444444],\n",
              "       [0.38095238],\n",
              "       [0.65079365],\n",
              "       [0.42857143],\n",
              "       [0.03174603],\n",
              "       [0.49206349],\n",
              "       [0.50793651],\n",
              "       [0.57142857],\n",
              "       [0.01587302],\n",
              "       [0.        ],\n",
              "       [0.57142857],\n",
              "       [0.44444444]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "971wQUAIw9WJ"
      },
      "source": [
        "- Finally, we need to convert the **output patterns (single characters converted to integers) into a one hot encoding.** \n",
        "\n",
        "- This is so that we can configure the network to predict the probability of each of the 63 different characters in the vocabulary (an easier representation) rather than trying to force it to predict precisely the next character.\n",
        "\n",
        "- Each **y value is converted into a sparse vector with a length of 63, full of zeros except with a 1 in the column for the letter (integer) that the pattern represents.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSG5y4Jlw9WO"
      },
      "source": [
        "# One hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIz-sJkrw9WQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca1fa24-44bd-422c-9131-e574cbb01c0b"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(573398, 63)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VexipY7Mw9WS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e80b64-1063-4585-cdef-d59cde6202fb"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF3WaqVsw9Wb"
      },
      "source": [
        "---\n",
        "<a name = Section5></a>\n",
        "# **5. Building LSTM Model**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO8xo2vJw9Wd"
      },
      "source": [
        "**<h4>Question 5:** Complete the function to build the LSTM model.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "- Define a single **LSTM** layer with **256** hidden units, specify `input_shape` equal to (X.shape[1], X.shape[2]).\n",
        "\n",
        "- The network should have a **Dropout** layer with dropout rate equal to **0.2** \n",
        " \n",
        "- The last layer of the network should be a **Dense** layer with hidden units equal to the number of classes to be predicted (i.e. equal to **y.shape[1]**), and an appropriate **activation** function for the last layer of a  **multiclass classification** problem.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9H8FSuow9We"
      },
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz0hYME6pgIK"
      },
      "source": [
        "model = build_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6R_xvHrv9HK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d82548-c233-4cc5-dd3f-41c120c39954"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 256)               264192    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 63)                16191     \n",
            "=================================================================\n",
            "Total params: 280,383\n",
            "Trainable params: 280,383\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYLJdkCdwA6S"
      },
      "source": [
        "**<h4>Question 6:** Complete the function to compile the model.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Use appropriate `loss` for a multiclass classification problem, with one-hot encoded target variable.\n",
        "\n",
        "- Use **adam** as the `optimizer`.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWPgMQrTpgDm"
      },
      "source": [
        "def compile_model(model):\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2PtQsAywSbi"
      },
      "source": [
        "model = compile_model(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-Zu23LGwflS"
      },
      "source": [
        "**<h4>Question 7:** Create Model Checkpoint callback object.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Use the following values for different parameters in the **ModelCheckpoint** class initiation:\n",
        "\n",
        "  - `filepath`: filepath\n",
        "\n",
        "  - `monitor`: 'loss'\n",
        "\n",
        "  - `save_best_only`: True\n",
        "  \n",
        "  - `mode`: 'min'\n",
        "\n",
        "  - `save_weights_only`: True\n",
        "  </details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baGpAEC_yNgc"
      },
      "source": [
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQildT8mw9Wg"
      },
      "source": [
        "def create_checkpoint(filepath):\n",
        "    checkpoint = ModelCheckpoint(filepath, monitor='loss', save_best_only=True, mode='min')\n",
        "\n",
        "    return checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruh7MRchySer"
      },
      "source": [
        "checkpoint = create_checkpoint(filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3H97MKInyQJa"
      },
      "source": [
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUI9qApEw9Wm"
      },
      "source": [
        "**<h4>Question 8:** Complete the function to train the Model\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Fit the model on **X** and **y**.\n",
        "\n",
        "- Specify:\n",
        "\n",
        "  - `epochs`: 20\n",
        "\n",
        "  - `batch_size`: 256\n",
        "\n",
        "  - `callbacks`: callbacks_list\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOumuGy3zN5i"
      },
      "source": [
        "def fit_model(model):\n",
        "    model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKeEQ9f5w9Wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4079a7fd-1c39-4ed0-9e10-a20580fd6343"
      },
      "source": [
        "model = fit_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "4480/4480 [==============================] - 164s 35ms/step - loss: 2.8202\n",
            "Epoch 2/20\n",
            "4480/4480 [==============================] - 157s 35ms/step - loss: 2.5938\n",
            "Epoch 3/20\n",
            "4480/4480 [==============================] - 157s 35ms/step - loss: 2.4989\n",
            "Epoch 4/20\n",
            "4480/4480 [==============================] - 157s 35ms/step - loss: 2.4174\n",
            "Epoch 5/20\n",
            "4480/4480 [==============================] - 155s 35ms/step - loss: 2.3531\n",
            "Epoch 6/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 2.2947\n",
            "Epoch 7/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 2.2438\n",
            "Epoch 8/20\n",
            "4480/4480 [==============================] - 155s 35ms/step - loss: 2.1996\n",
            "Epoch 9/20\n",
            "4480/4480 [==============================] - 157s 35ms/step - loss: 2.1597\n",
            "Epoch 10/20\n",
            "4480/4480 [==============================] - 158s 35ms/step - loss: 2.1266\n",
            "Epoch 11/20\n",
            "4480/4480 [==============================] - 158s 35ms/step - loss: 2.1009\n",
            "Epoch 12/20\n",
            "4480/4480 [==============================] - 158s 35ms/step - loss: 2.0717\n",
            "Epoch 13/20\n",
            "4480/4480 [==============================] - 157s 35ms/step - loss: 2.0521\n",
            "Epoch 14/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 2.0273\n",
            "Epoch 15/20\n",
            "4480/4480 [==============================] - 154s 34ms/step - loss: 2.0076\n",
            "Epoch 16/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 1.9900\n",
            "Epoch 17/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 1.9726\n",
            "Epoch 18/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 1.9580\n",
            "Epoch 19/20\n",
            "4480/4480 [==============================] - 154s 34ms/step - loss: 1.9446\n",
            "Epoch 20/20\n",
            "4480/4480 [==============================] - 153s 34ms/step - loss: 1.9322\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikIp-KyQw9Wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91ffd8fa-1626-4297-ad03-3d7ba0e5c67e"
      },
      "source": [
        "# To see the list of all weight checkpoint files created.\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\t\t\t    weights-improvement-11-2.1009.hdf5\n",
            "weights-improvement-01-2.8202.hdf5  weights-improvement-12-2.0717.hdf5\n",
            "weights-improvement-02-2.5938.hdf5  weights-improvement-13-2.0521.hdf5\n",
            "weights-improvement-03-2.4989.hdf5  weights-improvement-14-2.0273.hdf5\n",
            "weights-improvement-04-2.4174.hdf5  weights-improvement-15-2.0076.hdf5\n",
            "weights-improvement-05-2.3531.hdf5  weights-improvement-16-1.9900.hdf5\n",
            "weights-improvement-06-2.2947.hdf5  weights-improvement-17-1.9726.hdf5\n",
            "weights-improvement-07-2.2438.hdf5  weights-improvement-18-1.9580.hdf5\n",
            "weights-improvement-08-2.1996.hdf5  weights-improvement-19-1.9446.hdf5\n",
            "weights-improvement-09-2.1597.hdf5  weights-improvement-20-1.9322.hdf5\n",
            "weights-improvement-10-2.1266.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD48Lg8zw9Ws"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- After running the above code, you should have a number of weight checkpoint files in the local directory.\n",
        "\n",
        "- You can delete them all except the one with the smallest loss value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X45YQNV5w9Wv"
      },
      "source": [
        "---\n",
        "<a name = Section6></a>\n",
        "# **6. Generating Text with LSTM Network**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "batVB69zw9Wz"
      },
      "source": [
        "**<h4>Question 1:** Complete the function to load the model\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Replace the value of **filename** with the model weights having the least loss value during training.\n",
        "\n",
        "- Use model's `load_weights` method to load the saved model weights.\n",
        "\n",
        "- Specify **filename** as the model weights to be loaded.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J1ads6c06eJ"
      },
      "source": [
        "# Use the weight checkpoint file that has least loss value.\n",
        "filename = 'weights-improvement-20-1.9442.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kv_sbTlw9W4"
      },
      "source": [
        "def load_model(model, filename):\n",
        "    model.load_weights(filename)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mv9-bAOqDAC"
      },
      "source": [
        "model = load_model(model, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmqyjZIC2IUR"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYGBuEtCw9W7"
      },
      "source": [
        "**<h4>Question 10:** Create reverse mapping of integers to characters.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Enumerate through **`chars`** and store it as a dictionary.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYizI3xj6XCT"
      },
      "source": [
        "def int_to_char_fn(chars):\n",
        "    int_to_char = dict((i, c) for i, c in enumerate(chars))\n",
        "    \n",
        "    return int_to_char"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQhIsXmQw9W8"
      },
      "source": [
        "int_to_char = int_to_char_fn(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWiBRurV6h0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cdc6dbf-1e63-4d7d-c97e-d1d0a8ef6e99"
      },
      "source": [
        "int_to_char"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '\\n',\n",
              " 1: '\\r',\n",
              " 2: ' ',\n",
              " 3: '!',\n",
              " 4: '&',\n",
              " 5: '(',\n",
              " 6: ')',\n",
              " 7: ',',\n",
              " 8: '-',\n",
              " 9: '.',\n",
              " 10: '0',\n",
              " 11: '1',\n",
              " 12: '2',\n",
              " 13: '3',\n",
              " 14: '4',\n",
              " 15: '5',\n",
              " 16: '6',\n",
              " 17: '7',\n",
              " 18: '8',\n",
              " 19: '9',\n",
              " 20: ':',\n",
              " 21: ';',\n",
              " 22: '?',\n",
              " 23: '_',\n",
              " 24: 'a',\n",
              " 25: 'b',\n",
              " 26: 'c',\n",
              " 27: 'd',\n",
              " 28: 'e',\n",
              " 29: 'f',\n",
              " 30: 'g',\n",
              " 31: 'h',\n",
              " 32: 'i',\n",
              " 33: 'j',\n",
              " 34: 'k',\n",
              " 35: 'l',\n",
              " 36: 'm',\n",
              " 37: 'n',\n",
              " 38: 'o',\n",
              " 39: 'p',\n",
              " 40: 'q',\n",
              " 41: 'r',\n",
              " 42: 's',\n",
              " 43: 't',\n",
              " 44: 'u',\n",
              " 45: 'v',\n",
              " 46: 'w',\n",
              " 47: 'x',\n",
              " 48: 'y',\n",
              " 49: 'z',\n",
              " 50: '£',\n",
              " 51: '½',\n",
              " 52: 'à',\n",
              " 53: 'â',\n",
              " 54: 'æ',\n",
              " 55: 'è',\n",
              " 56: 'é',\n",
              " 57: 'œ',\n",
              " 58: '—',\n",
              " 59: '‘',\n",
              " 60: '’',\n",
              " 61: '“',\n",
              " 62: '”'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTxByqDbw9W_"
      },
      "source": [
        " - We will use this mapping to convert the integers back to characters so that we can understand the predictions.\n",
        "\n",
        " - Finally, we need to actually make predictions.\n",
        "\n",
        " - We can pick a random input pattern as our seed sequence, then print generated characters as we generate them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cmjliiK6liZ"
      },
      "source": [
        "# Pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsnJ5YZg6leM"
      },
      "source": [
        "pattern = dataX[start]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5WRxqvA6lZ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b47e381-4acd-4857-dc8c-0cdc6733397a"
      },
      "source": [
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" s him as\r\n",
            "either an innocent man, or else as a man of considerable self-restraint\r\n",
            "and firmness. as  \"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS5xPMU1w9XC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ddeb270-1b12-463c-fc10-232d3b4a230c"
      },
      "source": [
        "# Generate characters\n",
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "\n",
        "print(\"\\n\\nDone.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "and the mant of the correr of the seale of the coorert which hed hore\n",
            "the sealed oo the saale and the wert oore the saale and the coorert\n",
            "shitt of the correr of the saale and the coorer of the sealed waids\n",
            "fnrm the same oaner of the saale and the coorer of the wert sore, and\n",
            "\n",
            "\n",
            "seieht of the coorert which hed boeneed and sas an ond oane on the\n",
            "sererler of the saale and taake and taaken hnr she saale and taedie\n",
            "the sooe and a sereoner of the wert sorene oane on the saale and the\n",
            "sooe and taake and taaken hnr she saale and a sereoner of the wert\n",
            "coean and aaak and a seryere oa lent a sirgo of saaee and taake and\n",
            "\n",
            "the same was a seale and taake and a seryered aadk to the siae of the\n",
            "sooe and taake and taaken hnr sie saale and a\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJiHJ7I8w9XI"
      },
      "source": [
        "---\n",
        "<a name = Section7></a>\n",
        "# **7. Building Large LSTM Network**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMQsx7Vnw9XJ"
      },
      "source": [
        "**<h4>Question 11:** Complete the function to build a larger LSTM model.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        " - Define a network with two **LSTM** layer with **256** hidden units.\n",
        " \n",
        " - Specify `input_shape` equal to **(X.shape[1], X.shape[2])**, and `return_sequences` equal to **True**, in the first **LSTM** layer.\n",
        "\n",
        " - The network should have two **Dropout** layers with dropout rate equal to **0.2**, one after each **LSTM** layer. \n",
        " \n",
        "- The last layer of the network should be a **Dense** layer with hidden units equal to the number of classes to be predicted (i.e. equal to **y.shape[1]**), and an appropriate **activation** function for the last layer of a  **multiclass classification** problem.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7geDEO4w9I8p"
      },
      "source": [
        "def build_bigger_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(LSTM(256))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(y.shape[1], activation='softmax'))\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZy02lBc9I4Z"
      },
      "source": [
        "model = build_bigger_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xp5Shir9b0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ea7d79-ce11-4473-dd94-51b092c50236"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 100, 256)          264192    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 256)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 63)                16191     \n",
            "=================================================================\n",
            "Total params: 805,695\n",
            "Trainable params: 805,695\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLWYce6A9bv3"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdKqZHDC9brf"
      },
      "source": [
        "# Define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUPodq1Y9uk5"
      },
      "source": [
        "**<h4>Question 12:** Complete the function to train the Model.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Fit the model on **X** and **y**.\n",
        "\n",
        "- Specify:\n",
        "\n",
        "  - `epochs`: 50\n",
        "\n",
        "  - `batch_size`: 512\n",
        "\n",
        "  - `callbacks`: callbacks_list\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI5fb73J93ZP"
      },
      "source": [
        "def fit_bigger_model(model):\n",
        "    model.fit(X, y, epochs=50, batch_size=512, callbacks=callbacks_list)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V70P8sAiw9XJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b2fc216-dfbb-4f9b-aac8-38fc758204f5"
      },
      "source": [
        "model = fit_bigger_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1120/1120 [==============================] - 236s 208ms/step - loss: 2.8323\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.83228, saving model to weights-improvement-01-2.8323-bigger.hdf5\n",
            "Epoch 2/50\n",
            "1120/1120 [==============================] - 232s 207ms/step - loss: 2.4805\n",
            "\n",
            "Epoch 00002: loss improved from 2.83228 to 2.48050, saving model to weights-improvement-02-2.4805-bigger.hdf5\n",
            "Epoch 3/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 2.3055\n",
            "\n",
            "Epoch 00003: loss improved from 2.48050 to 2.30547, saving model to weights-improvement-03-2.3055-bigger.hdf5\n",
            "Epoch 4/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 2.1901\n",
            "\n",
            "Epoch 00004: loss improved from 2.30547 to 2.19012, saving model to weights-improvement-04-2.1901-bigger.hdf5\n",
            "Epoch 5/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 2.1009\n",
            "\n",
            "Epoch 00005: loss improved from 2.19012 to 2.10088, saving model to weights-improvement-05-2.1009-bigger.hdf5\n",
            "Epoch 6/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 2.0392\n",
            "\n",
            "Epoch 00006: loss improved from 2.10088 to 2.03923, saving model to weights-improvement-06-2.0392-bigger.hdf5\n",
            "Epoch 7/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.9838\n",
            "\n",
            "Epoch 00007: loss improved from 2.03923 to 1.98379, saving model to weights-improvement-07-1.9838-bigger.hdf5\n",
            "Epoch 8/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.9429\n",
            "\n",
            "Epoch 00008: loss improved from 1.98379 to 1.94287, saving model to weights-improvement-08-1.9429-bigger.hdf5\n",
            "Epoch 9/50\n",
            "1120/1120 [==============================] - 232s 207ms/step - loss: 1.9062\n",
            "\n",
            "Epoch 00009: loss improved from 1.94287 to 1.90615, saving model to weights-improvement-09-1.9062-bigger.hdf5\n",
            "Epoch 10/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.8744\n",
            "\n",
            "Epoch 00010: loss improved from 1.90615 to 1.87441, saving model to weights-improvement-10-1.8744-bigger.hdf5\n",
            "Epoch 11/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.8479\n",
            "\n",
            "Epoch 00011: loss improved from 1.87441 to 1.84793, saving model to weights-improvement-11-1.8479-bigger.hdf5\n",
            "Epoch 12/50\n",
            "1120/1120 [==============================] - 232s 207ms/step - loss: 1.8216\n",
            "\n",
            "Epoch 00012: loss improved from 1.84793 to 1.82162, saving model to weights-improvement-12-1.8216-bigger.hdf5\n",
            "Epoch 13/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.8023\n",
            "\n",
            "Epoch 00013: loss improved from 1.82162 to 1.80232, saving model to weights-improvement-13-1.8023-bigger.hdf5\n",
            "Epoch 14/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.7828\n",
            "\n",
            "Epoch 00014: loss improved from 1.80232 to 1.78284, saving model to weights-improvement-14-1.7828-bigger.hdf5\n",
            "Epoch 15/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.7626\n",
            "\n",
            "Epoch 00015: loss improved from 1.78284 to 1.76262, saving model to weights-improvement-15-1.7626-bigger.hdf5\n",
            "Epoch 16/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.7509\n",
            "\n",
            "Epoch 00016: loss improved from 1.76262 to 1.75094, saving model to weights-improvement-16-1.7509-bigger.hdf5\n",
            "Epoch 17/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.7305\n",
            "\n",
            "Epoch 00017: loss improved from 1.75094 to 1.73053, saving model to weights-improvement-17-1.7305-bigger.hdf5\n",
            "Epoch 18/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.7158\n",
            "\n",
            "Epoch 00018: loss improved from 1.73053 to 1.71585, saving model to weights-improvement-18-1.7158-bigger.hdf5\n",
            "Epoch 19/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.7115\n",
            "\n",
            "Epoch 00019: loss improved from 1.71585 to 1.71153, saving model to weights-improvement-19-1.7115-bigger.hdf5\n",
            "Epoch 20/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.6920\n",
            "\n",
            "Epoch 00020: loss improved from 1.71153 to 1.69202, saving model to weights-improvement-20-1.6920-bigger.hdf5\n",
            "Epoch 21/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.6794\n",
            "\n",
            "Epoch 00021: loss improved from 1.69202 to 1.67943, saving model to weights-improvement-21-1.6794-bigger.hdf5\n",
            "Epoch 22/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.6700\n",
            "\n",
            "Epoch 00022: loss improved from 1.67943 to 1.66997, saving model to weights-improvement-22-1.6700-bigger.hdf5\n",
            "Epoch 23/50\n",
            "1120/1120 [==============================] - 234s 209ms/step - loss: 1.6594\n",
            "\n",
            "Epoch 00023: loss improved from 1.66997 to 1.65944, saving model to weights-improvement-23-1.6594-bigger.hdf5\n",
            "Epoch 24/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.6507\n",
            "\n",
            "Epoch 00024: loss improved from 1.65944 to 1.65073, saving model to weights-improvement-24-1.6507-bigger.hdf5\n",
            "Epoch 25/50\n",
            "1120/1120 [==============================] - 234s 209ms/step - loss: 1.6459\n",
            "\n",
            "Epoch 00025: loss improved from 1.65073 to 1.64595, saving model to weights-improvement-25-1.6459-bigger.hdf5\n",
            "Epoch 26/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.6327\n",
            "\n",
            "Epoch 00026: loss improved from 1.64595 to 1.63274, saving model to weights-improvement-26-1.6327-bigger.hdf5\n",
            "Epoch 27/50\n",
            "1120/1120 [==============================] - 233s 208ms/step - loss: 1.6236\n",
            "\n",
            "Epoch 00027: loss improved from 1.63274 to 1.62355, saving model to weights-improvement-27-1.6236-bigger.hdf5\n",
            "Epoch 28/50\n",
            "  59/1120 [>.............................] - ETA: 3:39 - loss: 1.6048"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SxTp8wTw9XL"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dRAu52zw9XO"
      },
      "source": [
        "---\n",
        "<a name = Section8></a>\n",
        "# **8. Generating Text**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRfoPn1W-56e"
      },
      "source": [
        "**<h4>Question 13:** Complete the function to load the model.\n",
        "\n",
        "<details>\n",
        "\n",
        "**<summary>Hint:</summary>**\n",
        "\n",
        "- Replace the value of **filename** with the model weights having the least loss value during training.\n",
        "\n",
        "- Use model's `load_weights` method to load the saved model weights.\n",
        "\n",
        "- Specify **filename** as the model weights to be loaded.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCfJq42J_Bzy"
      },
      "source": [
        "# Use the weight checkpoint file that has least loss value.\n",
        "filename = 'weights-improvement-50-1.4850-bigger.hdf5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APGb2Itw_Bz3"
      },
      "source": [
        "def load_bigger_model(model, filename):\n",
        "    model.load_weights(filename)\n",
        "\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc40HGHO_Bz4"
      },
      "source": [
        "model = load_bigger_model(model, filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUOEDdo-_I5Q"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awpkZZkg_Nps"
      },
      "source": [
        "# Pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEWzY0-q_Npu"
      },
      "source": [
        "pattern = dataX[start]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WosDBhLz_Npz"
      },
      "source": [
        "print(\"Seed:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX5477v0_Np9"
      },
      "source": [
        "# Generate characters\n",
        "for i in range(1000):\n",
        "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
        "    x = x / float(n_vocab)\n",
        "    prediction = model.predict(x, verbose=0)\n",
        "    index = np.argmax(prediction)\n",
        "    result = int_to_char[index]\n",
        "    seq_in = [int_to_char[value] for value in pattern]\n",
        "    sys.stdout.write(result)\n",
        "    pattern.append(index)\n",
        "    pattern = pattern[1:len(pattern)]\n",
        "\n",
        "print(\"\\n\\nDone.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzEayrtKSMvl"
      },
      "source": [
        "---\n",
        "<a name = Section9></a>\n",
        "# **9. Conclusion**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMUBFMnjZNas"
      },
      "source": [
        "- From the above implementations we get an idea bout generating text using LSTM models.\n",
        "\n",
        "- We learned how to **pre-process** the raw text data into a suitable format.\n",
        "\n",
        "- Using the processed text we build our LSTM model to generate text. \n",
        "- We also learned to save our model and load our model.\n",
        "\n",
        "- You can further try experimenting with different model architecture and try to improve the performance of the model."
      ]
    }
  ]
}